"""
SASTRE Cognitive Engine - The Rotating Gap-Analyzer (V4.2 Sensor)

The Grid is not a database view; it is the system's brain.
The system does not merely "check for empty fields."
It actively THINKS by rotating through four Cognitive Modes (Centricities).

Each rotation reveals gaps that the others miss.

Architecture:
    Gap = (Subject Axis × Location Axis × Nexus Axis)

Cognitive Modes:
    A. NARRATIVE-CENTRIC (The Editor) - Story coherence
    B. SUBJECT-CENTRIC (The Biographer) - Profile completeness
    C. LOCATION-CENTRIC (The Cartographer) - Terrain coverage
    D. NEXUS-CENTRIC (The Detective) - Connection logic
"""

import asyncio
import logging
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple, Set
from datetime import datetime
from collections import defaultdict

# Import the REAL schema reader (from CYMONIDES authoritative source)
from ..contracts import KUQuadrant, derive_quadrant, NarrativeGovernor, UnifiedSlot
from .cognitive_types import (
    CognitiveMode,
    GapDimension,
    CertaintyLevel,
    SubjectAxis,
    LocationAxis,
    NexusAxis,
    GapCoordinates3D,
    CognitiveGap,
)
from .narrative_assessor import NarrativeAssessor
from .subject_assessor import SubjectAssessor
from .location_assessor import LocationAssessor
from .nexus_assessor import NexusAssessor

logger = logging.getLogger(__name__)


# =============================================================================
# CROSS-POLLINATION ACTION
# =============================================================================

@dataclass
class CrossPollinationAction:
    """
    An action generated by cross-pollination between modes.

    Insights from one mode drive actions in another.
    """
    source_mode: CognitiveMode
    target_mode: CognitiveMode
    insight: str                         # What we learned
    action: str                          # What to do about it
    priority: int = 50

    # The gap this spawns
    spawned_gap: Optional[CognitiveGap] = None


# =============================================================================
# DIMENSIONAL ANALYSIS
# =============================================================================

@dataclass
class DimensionalCorrelation:
    """Result of correlating entities across a dimension."""
    dimension: GapDimension
    entities: List[str]                  # Entity IDs that correlate
    overlap_value: Any                   # The shared value (location, time, source)
    significance: float                  # How noteworthy (0-1)
    insight: str


@dataclass
class DimensionalContrast:
    """Result of contrasting entities across a dimension."""
    dimension: GapDimension
    entity_a: str
    entity_b: str
    divergence_value: Any               # Where they differ
    significance: float
    insight: str
    is_suspicious: bool = False          # Unexpected divergence


@dataclass
class DimensionalAnalysis:
    """Complete dimensional analysis results."""
    correlations: List[DimensionalCorrelation] = field(default_factory=list)
    contrasts: List[DimensionalContrast] = field(default_factory=list)

    def significant_findings(self, threshold: float = 0.5) -> List[str]:
        """Get insights above significance threshold."""
        findings = []
        for c in self.correlations:
            if c.significance >= threshold:
                findings.append(f"CORRELATE: {c.insight}")
        for c in self.contrasts:
            if c.significance >= threshold:
                findings.append(f"CONTRAST: {c.insight}")
        return findings


# =============================================================================
# CORPUS CHECK
# =============================================================================

@dataclass
class CorpusCheckResult:
    """
    Result of checking the corpus for Unknown Knowns.

    The "Old Lady on the Corner" principle:
    Information we already possess becomes relevant only when context changes.
    """
    query: str
    found_nodes: List[Dict[str, Any]] = field(default_factory=list)
    found_edges: List[Dict[str, Any]] = field(default_factory=list)
    dormant_connections: List[Tuple[str, str]] = field(default_factory=list)

    @property
    def has_unknown_knowns(self) -> bool:
        return bool(self.found_nodes or self.found_edges or self.dormant_connections)

    def summary(self) -> str:
        if not self.has_unknown_knowns:
            return "No existing data found"
        parts = []
        if self.found_nodes:
            parts.append(f"{len(self.found_nodes)} relevant nodes")
        if self.dormant_connections:
            parts.append(f"{len(self.dormant_connections)} dormant connections")
        return f"Found: {', '.join(parts)}"


# =============================================================================
# COGNITIVE ENGINE (THE BRAIN)
# =============================================================================

class CognitiveEngine:
    """
    The Rotating Gap-Analyzer.

    Rotates through four Cognitive Modes to identify gaps with 3D coordinates.
    Performs corpus checks, dimensional analysis, and cross-pollination.

    This is the system's BRAIN, not just a view.

    The NarrativeGovernor (if provided) acts as the stopping condition:
    - Filters gaps based on remaining word budget
    - Prioritizes gaps that serve required sections
    - Stops drilling when template requirements are met
    """

    def __init__(
        self,
        state: Any,                       # InvestigationState
        corpus_client: Any = None,        # CymonidesClient for corpus checks
        graph_provider: Any = None,       # For graph queries
        governor: Optional[NarrativeGovernor] = None,  # Template-based stopping conditions
    ):
        self.state = state
        self.corpus_client = corpus_client
        self.graph_provider = graph_provider
        self.governor = governor

        # Results
        self._gaps: List[CognitiveGap] = []
        self._slots: List[UnifiedSlot] = []
        self._cross_pollinations: List[CrossPollinationAction] = []
        self._dimensional_analysis: Optional[DimensionalAnalysis] = None
        self._corpus_results: Dict[str, CorpusCheckResult] = {}

        # Mode-specific gap counts
        self._mode_gaps: Dict[CognitiveMode, int] = {m: 0 for m in CognitiveMode}

        # Governor-filtered gaps
        self._filtered_gaps: List[CognitiveGap] = []

        # Mode assessors
        self._narrative_assessor = NarrativeAssessor(state)
        self._subject_assessor = SubjectAssessor(state)
        self._location_assessor = LocationAssessor(state)
        self._nexus_assessor = NexusAssessor(state)

    async def analyze(self) -> List[CognitiveGap]:
        """
        Run the full cognitive analysis.

        V4.2 SENSOR FLOW:
            Grid State → K-U Mapping (sensor output)

        1. ROTATE through all four modes (identify gaps)
        2. CORPUS CHECK for Unknown Knowns
        3. CLASSIFY K-U STATE (Known/Unknown axes)
        4. DIMENSIONAL ANALYSIS (correlate/contrast)
        5. CROSS-POLLINATE between modes
        6. PRIORITIZE gaps
        """
        logger.info("=== COGNITIVE ENGINE: Starting rotation ===")

        # 1. ROTATE THROUGH CENTRICITIES
        await self._rotate_modes()

        # 2. CORPUS CHECK
        await self._check_corpus()

        # 3. CLASSIFY K-U STATE (sensor output only)
        self._classify_ku_states()

        # 4. DIMENSIONAL ANALYSIS
        await self._analyze_dimensions()

        # 5. CROSS-POLLINATION
        self._cross_pollinate()

        # 6. PRIORITIZE
        self._prioritize_gaps()

        # Update unified slot view (gap is a view over slots)
        self._slots = [g.slot for g in self._gaps if getattr(g, "slot", None)]

        logger.info(f"=== COGNITIVE ENGINE: Found {len(self._gaps)} gaps ===")
        for mode, count in self._mode_gaps.items():
            logger.info(f"    {mode.value.upper()}: {count} gaps")

        # Log K-U distribution
        ku_counts = defaultdict(int)
        for gap in self._gaps:
            if gap.ku_quadrant:
                ku_counts[gap.ku_quadrant.value] += 1
        logger.info(f"  K-U Distribution: {dict(ku_counts)}")

        return self._gaps

    # ─────────────────────────────────────────────────────────────────────────
    # MODE ROTATION
    # ─────────────────────────────────────────────────────────────────────────

    async def _rotate_modes(self):
        """Rotate through all four cognitive modes."""

        # MODE A: NARRATIVE (The Editor)
        logger.info("  [A] NARRATIVE MODE: Assessing story coherence...")
        narrative_gaps = self._narrative_assessor.assess()
        self._gaps.extend(narrative_gaps)
        self._mode_gaps[CognitiveMode.NARRATIVE] = len(narrative_gaps)

        # MODE B: SUBJECT (The Biographer)
        logger.info("  [B] SUBJECT MODE: Assessing profile completeness...")
        subject_gaps = self._subject_assessor.assess()
        self._gaps.extend(subject_gaps)
        self._mode_gaps[CognitiveMode.SUBJECT] = len(subject_gaps)

        # MODE C: LOCATION (The Cartographer)
        logger.info("  [C] LOCATION MODE: Assessing terrain coverage...")
        location_gaps = self._location_assessor.assess()
        self._gaps.extend(location_gaps)
        self._mode_gaps[CognitiveMode.LOCATION] = len(location_gaps)

        # MODE D: NEXUS (The Detective)
        logger.info("  [D] NEXUS MODE: Assessing connection logic...")
        nexus_gaps = await self._nexus_assessor.assess()
        self._gaps.extend(nexus_gaps)
        self._mode_gaps[CognitiveMode.NEXUS] = len(nexus_gaps)

    # ─────────────────────────────────────────────────────────────────────────
    # CORPUS CHECK
    # ─────────────────────────────────────────────────────────────────────────

    async def _check_corpus(self):
        """
        Check for Unknown Knowns in the corpus.

        The "Old Lady on the Corner" principle:
        Information we already possess becomes relevant only when context changes.
        """
        logger.info("  CORPUS CHECK: Searching for Unknown Knowns...")

        if not self.corpus_client:
            logger.info("    No corpus client - skipping")
            return

        for gap in self._gaps:
            # Build corpus query from gap coordinates
            corpus_query = self._build_corpus_query(gap.coordinates)

            if not corpus_query:
                continue

            result = await self._execute_corpus_query(corpus_query)
            self._corpus_results[gap.id] = result

            if result.has_unknown_knowns:
                gap.corpus_checked = True
                gap.found_in_corpus = True
                gap.corpus_node_ids = [n.get('id', '') for n in result.found_nodes]
                gap.priority -= 30  # Lower priority - we already have data

                logger.info(f"    Found Unknown Known for '{gap.id}': {result.summary()}")

    def _build_corpus_query(self, coords: GapCoordinates3D) -> str:
        """Build a corpus search query from gap coordinates."""
        parts = []

        if coords.subject.entity_name:
            parts.append(coords.subject.entity_name)

        if coords.subject.attribute:
            parts.append(coords.subject.attribute)

        if coords.location.jurisdiction:
            parts.append(coords.location.jurisdiction)

        return " ".join(parts) if parts else ""

    async def _execute_corpus_query(self, query: str) -> CorpusCheckResult:
        """Execute a query against the corpus."""
        result = CorpusCheckResult(query=query)

        if not self.corpus_client:
            return result

        try:
            # Search for matching nodes
            nodes = await self.corpus_client.search_nodes(query)
            result.found_nodes = nodes[:10]  # Limit results

            # Check for dormant connections
            if self.graph_provider and nodes:
                for node in nodes:
                    node_id = node.get('id', '')
                    if node_id:
                        related = await self.graph_provider.get_related_nodes(node_id)
                        for rel in related:
                            if not rel.get('connected', True):
                                result.dormant_connections.append((node_id, rel.get('id', '')))

        except Exception as e:
            logger.debug(f"Corpus query failed: {e}")

        return result

    # ─────────────────────────────────────────────────────────────────────────
    # K-U STATE CLASSIFICATION (Sensor Output)
    # ─────────────────────────────────────────────────────────────────────────

    def _classify_ku_states(self):
        """
        Classify K-U state for each gap without deriving intent.

        This produces the sensor output (subject_known/location_known + quadrant)
        that the orchestrator uses to derive intent.
        """
        logger.info("  K-U CLASSIFICATION: Mapping known/unknown axes...")

        for gap in self._gaps:
            subject_known = self._assess_subject_knowledge(gap.coordinates.subject)
            location_known = self._assess_location_knowledge(gap.coordinates.location)

            gap.subject_known = subject_known
            gap.location_known = location_known
            gap.ku_quadrant = derive_quadrant(subject_known, location_known)

    def _assess_subject_knowledge(self, subject: SubjectAxis) -> bool:
        """
        Assess whether we KNOW the subject or not.

        Known = We have an entity ID AND name AND type.
        Unknown = We're searching for who/what.
        """
        has_entity = bool(subject.entity_id or subject.entity_name)
        has_type = bool(subject.entity_type)

        # If we have entity identity, check if it's in our state
        if has_entity and has_type:
            # Check if entity exists in state
            entity_id = subject.entity_id
            if entity_id:
                entities = getattr(self.state, 'entities', {})
                if entity_id in entities:
                    entity = entities[entity_id]
                    # Known if core is complete
                    if hasattr(entity, 'core_complete') and entity.core_complete:
                        return True
                    # Partially known if entity exists
                    return True

            # If we have name but not ID, we still "know" the subject
            if subject.entity_name:
                return True

        return False

    def _assess_location_knowledge(self, location: LocationAxis) -> bool:
        """
        Assess whether we KNOW the location or not.

        Known = We have jurisdiction/domain/source_type defined.
        Unknown = We need to discover where to look.
        """
        has_jurisdiction = bool(location.jurisdiction)
        has_location_domain = bool(location.domain)
        has_source_type = bool(location.source_type)

        # Known if we have at least jurisdiction or domain
        if has_jurisdiction or has_location_domain:
            # Check if we've checked this location
            sources = getattr(self.state, 'sources', {})
            for source in sources.values():
                source_jur = getattr(source, 'jurisdiction', None)
                source_domain = getattr(source, 'domain', None)

                if source_jur == location.jurisdiction or source_domain == location.domain:
                    # We know about this location
                    return True

            # If we have jurisdiction/domain defined, we "know" the location
            return has_jurisdiction or has_location_domain

        return False


    # DIMENSIONAL ANALYSIS
    # ─────────────────────────────────────────────────────────────────────────

    async def _analyze_dimensions(self):
        """
        Analyze entities across dimensions (Correlate & Contrast).

        CORRELATE (Overlap):
            - Geo: Where do Entity A and B both appear?
            - Temporal: When do they co-occur?
            - Source: Which sources mention both?

        CONTRAST (Delta):
            - Geo: Where does A appear that B does not?
            - Source: What does the Registry say vs. the News?
            - Temporal: What changed between 2020 and 2024?
        """
        logger.info("  DIMENSIONAL ANALYSIS: Correlating and contrasting...")

        self._dimensional_analysis = DimensionalAnalysis()

        entities = list(getattr(self.state, 'entities', {}).values())

        if len(entities) < 2:
            return

        # Geographic correlation/contrast
        await self._analyze_geographic_dimension(entities)

        # Temporal correlation/contrast
        await self._analyze_temporal_dimension(entities)

        # Source correlation/contrast
        await self._analyze_source_dimension(entities)

        # Log significant findings
        findings = self._dimensional_analysis.significant_findings()
        for f in findings[:5]:
            logger.info(f"    {f}")

    async def _analyze_geographic_dimension(self, entities: List[Any]):
        """Analyze geographic correlations and contrasts."""
        # Group by jurisdiction
        by_jur: Dict[str, List[str]] = defaultdict(list)

        for entity in entities:
            entity_id = getattr(entity, 'id', str(entity))
            shell = getattr(entity, 'shell', {})
            if 'jurisdiction' in shell:
                jur = shell['jurisdiction']
                jur_val = jur.value if hasattr(jur, 'value') else str(jur)
                by_jur[jur_val].append(entity_id)

        # Find correlations (multiple entities in same jurisdiction)
        for jur, entity_ids in by_jur.items():
            if len(entity_ids) > 1:
                self._dimensional_analysis.correlations.append(
                    DimensionalCorrelation(
                        dimension=GapDimension.GEOGRAPHIC,
                        entities=entity_ids,
                        overlap_value=jur,
                        significance=min(len(entity_ids) / 5, 1.0),
                        insight=f"{len(entity_ids)} entities share jurisdiction: {jur}"
                    )
                )

    async def _analyze_temporal_dimension(self, entities: List[Any]):
        """Analyze temporal correlations and contrasts."""
        # This would compare temporal attributes like incorporation dates,
        # event dates, etc. Implementation depends on entity structure.
        pass

    async def _analyze_source_dimension(self, entities: List[Any]):
        """Analyze source correlations and contrasts."""
        # Check which sources mention which entities
        sources = getattr(self.state, 'sources', {})
        source_to_entities = getattr(self.state, 'source_to_entities', {})

        for source_id, entity_ids in source_to_entities.items():
            if len(entity_ids) > 1:
                source = sources.get(source_id)
                source_name = getattr(source, 'source_name', source_id) if source else source_id

                self._dimensional_analysis.correlations.append(
                    DimensionalCorrelation(
                        dimension=GapDimension.SOURCE,
                        entities=list(entity_ids),
                        overlap_value=source_name,
                        significance=min(len(entity_ids) / 3, 1.0),
                        insight=f"{len(entity_ids)} entities appear in: {source_name}"
                    )
                )

    # ─────────────────────────────────────────────────────────────────────────
    # CROSS-POLLINATION
    # ─────────────────────────────────────────────────────────────────────────

    def _cross_pollinate(self):
        """
        Cross-pollinate insights between modes.

        Insights from one mode drive actions in another.
        """
        logger.info("  CROSS-POLLINATION: Connecting insights to actions...")

        entities = getattr(self.state, 'entities', {})
        sources = getattr(self.state, 'sources', {})

        # SUBJECT → LOCATION: Entity implies jurisdiction to check
        for entity_id, entity in entities.items():
            shell = getattr(entity, 'shell', {})
            if 'jurisdiction' in shell:
                jur = shell['jurisdiction']
                jur_val = jur.value if hasattr(jur, 'value') else str(jur)
                entity_name = getattr(entity, 'name', entity_id)

                # Check if we've explored this jurisdiction
                jur_sources = [s for s in sources.values()
                              if getattr(s, 'jurisdiction', '') == jur_val]
                unchecked = [s for s in jur_sources
                            if getattr(s, 'state', None) and s.state.value == 'unchecked']

                if unchecked:
                    action = CrossPollinationAction(
                        source_mode=CognitiveMode.SUBJECT,
                        target_mode=CognitiveMode.LOCATION,
                        insight=f"Entity {entity_name} implies jurisdiction {jur_val}",
                        action=f"Check {len(unchecked)} unchecked sources in {jur_val}",
                        priority=60,
                    )
                    self._cross_pollinations.append(action)

        # LOCATION → SUBJECT: Source checked but entities not extracted
        source_to_entities = getattr(self.state, 'source_to_entities', {})
        for source_id, source in sources.items():
            if getattr(source, 'state', None) and source.state.value == 'checked':
                raw_results = getattr(source, 'raw_results', 0)
                entity_count = len(source_to_entities.get(source_id, []))

                if raw_results > 0 and entity_count == 0:
                    action = CrossPollinationAction(
                        source_mode=CognitiveMode.LOCATION,
                        target_mode=CognitiveMode.SUBJECT,
                        insight=f"Source {source.source_name} has results but no extracted entities",
                        action=f"Run entity extraction on {source.source_name}",
                        priority=55,
                    )
                    self._cross_pollinations.append(action)

        # NEXUS → NARRATIVE: Connection implies story question
        graph = getattr(self.state, 'graph', None)
        if graph:
            for edge in getattr(graph, 'edges', []):
                if not getattr(edge, 'confirmed', True):
                    source_entity = entities.get(edge.source_entity_id)
                    target_entity = entities.get(edge.target_entity_id)

                    if source_entity and target_entity:
                        action = CrossPollinationAction(
                            source_mode=CognitiveMode.NEXUS,
                            target_mode=CognitiveMode.NARRATIVE,
                            insight=f"Unconfirmed link: {source_entity.name} ↔ {target_entity.name}",
                            action=f"Add narrative question: Why are they connected?",
                            priority=50,
                        )
                        self._cross_pollinations.append(action)

        logger.info(f"    Generated {len(self._cross_pollinations)} cross-pollination actions")

    # ─────────────────────────────────────────────────────────────────────────
    # GOVERNOR-BASED GAP FILTERING
    # ─────────────────────────────────────────────────────────────────────────

    def _should_pursue_gap(self, gap: CognitiveGap) -> bool:
        """
        Ask the Governor: Should we pursue this gap?

        The Governor decides based on:
        1. Should we continue drilling at all?
        2. Does this gap serve a required section?
        3. Do we have word budget remaining?

        If no governor is set, always pursue (backwards compatible).
        """
        if not self.governor:
            return True

        # Check if we should continue at all
        if not self.governor.should_continue_drilling():
            logger.debug(f"Governor: Stop drilling - template requirements met")
            return False

        # Boost priority for gaps that serve missing sections
        missing_sections = self.governor.get_missing_sections()
        if missing_sections:
            gap_section = self._infer_section_from_gap(gap)
            if gap_section and any(s.lower() in gap_section.lower() for s in missing_sections):
                # This gap serves a required section - definitely pursue
                gap.priority += 20
                return True

        # Check word budget - if we're at 90% capacity, only pursue high-priority
        budget_ratio = self.governor.current_word_count / self.governor.max_word_count
        if budget_ratio > 0.9:
            # Only pursue critical gaps (priority > 70)
            if gap.priority < 70:
                logger.debug(f"Governor: Skip gap '{gap.id}' - low priority, near word limit")
                return False

        return True

    def _infer_section_from_gap(self, gap: CognitiveGap) -> Optional[str]:
        """Infer which report section a gap would contribute to."""
        desc_lower = gap.description.lower()
        intent_lower = gap.coordinates.narrative_intent.lower()

        # Map gap descriptions to section types
        section_mappings = {
            "executive_summary": ["overview", "summary", "key finding"],
            "background": ["founding", "establishment", "history", "background"],
            "ownership_and_management": ["officer", "director", "shareholder", "owner", "management"],
            "corporate_structure": ["subsidiary", "parent", "structure", "affiliate"],
            "litigation": ["court", "lawsuit", "litigation", "legal", "judgment"],
            "adverse_information": ["adverse", "allegation", "sanction", "negative"],
            "media_profile": ["media", "news", "press", "coverage"],
        }

        for section, keywords in section_mappings.items():
            if any(kw in desc_lower or kw in intent_lower for kw in keywords):
                return section

        return None

    # ─────────────────────────────────────────────────────────────────────────
    # PRIORITIZATION
    # ─────────────────────────────────────────────────────────────────────────

    def _prioritize_gaps(self):
        """
        Prioritize gaps by narrative weight and governor constraints.

        If a governor is present, gaps are filtered through _should_pursue_gap()
        before final prioritization.
        """
        # First pass: apply base priority adjustments
        for gap in self._gaps:
            # Boost for narrative-centric gaps (story coherence matters most)
            if gap.discovered_by_mode == CognitiveMode.NARRATIVE:
                gap.priority += 10

            # Boost for disambiguation needs
            if gap.coordinates.nexus.surprising_absence:
                gap.priority += 15

            # Reduce priority if found in corpus
            if gap.found_in_corpus:
                gap.priority -= 30

            # Clamp to valid range
            gap.priority = max(0, min(100, gap.priority))

        # Second pass: filter through governor
        if self.governor:
            self._filtered_gaps = [g for g in self._gaps if self._should_pursue_gap(g)]
            filtered_count = len(self._gaps) - len(self._filtered_gaps)
            if filtered_count > 0:
                logger.info(f"    Governor filtered {filtered_count} gaps (word budget/priority)")
        else:
            self._filtered_gaps = self._gaps.copy()

        # Sort by priority (highest first)
        self._gaps.sort(key=lambda g: g.priority, reverse=True)
        self._filtered_gaps.sort(key=lambda g: g.priority, reverse=True)

    # ─────────────────────────────────────────────────────────────────────────
    # PUBLIC INTERFACE
    # ─────────────────────────────────────────────────────────────────────────

    def get_gaps(self) -> List[CognitiveGap]:
        """Get all gaps found."""
        return self._gaps

    def get_slots(self) -> List[UnifiedSlot]:
        """Get unified slot view (unsatisfied requirements)."""
        return self._slots

    def get_top_gaps(self, n: int = 10) -> List[CognitiveGap]:
        """Get top N gaps by priority."""
        return self._gaps[:n]

    def get_gaps_by_mode(self, mode: CognitiveMode) -> List[CognitiveGap]:
        """Get gaps discovered by a specific mode."""
        return [g for g in self._gaps if g.discovered_by_mode == mode]

    def get_cross_pollinations(self) -> List[CrossPollinationAction]:
        """Get cross-pollination actions."""
        return self._cross_pollinations

    def get_corpus_results(self) -> Dict[str, CorpusCheckResult]:
        """Get corpus check results."""
        return self._corpus_results

    def get_dimensional_analysis(self) -> Optional[DimensionalAnalysis]:
        """Get dimensional analysis results."""
        return self._dimensional_analysis

    def get_governor_filtered_gaps(self) -> List[CognitiveGap]:
        """
        Get gaps filtered by the NarrativeGovernor.

        These are gaps that passed the governor's should_pursue check.
        Use these for query generation when word budget matters.
        """
        return self._filtered_gaps

    def get_governor_status(self) -> Dict[str, Any]:
        """Get current governor status (for UI display)."""
        if not self.governor:
            return {"active": False}

        return {
            "active": True,
            "genre": self.governor.genre,
            "depth": self.governor.depth_level.value,
            "word_count": self.governor.current_word_count,
            "max_words": self.governor.max_word_count,
            "word_budget_remaining": self.governor.get_remaining_budget(),
            "iteration": self.governor.current_iteration,
            "max_iterations": self.governor.max_drill_iterations,
            "sections_filled": list(self.governor.sections_filled),
            "sections_missing": self.governor.get_missing_sections(),
            "should_continue": self.governor.should_continue_drilling(),
        }

    def summary(self) -> Dict[str, Any]:
        """Get summary of cognitive analysis."""
        result = {
            "total_gaps": len(self._gaps),
            "gaps_by_mode": {m.value: self._mode_gaps[m] for m in CognitiveMode},
            "corpus_hits": sum(1 for g in self._gaps if g.found_in_corpus),
            "cross_pollinations": len(self._cross_pollinations),
            "dimensional_findings": len(self._dimensional_analysis.significant_findings()) if self._dimensional_analysis else 0,
        }

        # Add governor info if present
        if self.governor:
            result["governor"] = {
                "filtered_gaps": len(self._filtered_gaps),
                "dropped_gaps": len(self._gaps) - len(self._filtered_gaps),
                "word_budget_used": f"{self.governor.current_word_count}/{self.governor.max_word_count}",
                "should_continue": self.governor.should_continue_drilling(),
            }

        return result


# =============================================================================
# CONVENIENCE FUNCTION
# =============================================================================

async def run_cognitive_analysis(
    state: Any,
    corpus_client: Any = None,
    graph_provider: Any = None,
    governor: Optional[NarrativeGovernor] = None,
) -> Tuple[List[CognitiveGap], List[CrossPollinationAction]]:
    """
    Run full cognitive analysis and return gaps + cross-pollinations.

    Args:
        state: InvestigationState with entities, sources, graph
        corpus_client: Optional CymonidesClient for corpus checks
        graph_provider: Optional graph query provider
        governor: Optional NarrativeGovernor for template-based filtering

    Returns:
        Tuple of (gaps, cross_pollinations). If governor is provided,
        gaps are filtered based on word budget and section requirements.
    """
    engine = CognitiveEngine(state, corpus_client, graph_provider, governor)
    gaps = await engine.analyze()
    cross_pollinations = engine.get_cross_pollinations()

    # Return governor-filtered gaps if governor is present
    if governor:
        return engine.get_governor_filtered_gaps(), cross_pollinations

    return gaps, cross_pollinations
